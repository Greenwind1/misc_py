{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-Packages\" data-toc-modified-id=\"Load-Packages-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load Packages</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Sentence\" data-toc-modified-id=\"Sentence-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Sentence</a></span></li><li><span><a href=\"#Memorization\" data-toc-modified-id=\"Memorization-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Memorization</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Random Forest</a></span><ul class=\"toc-item\"><li><span><a href=\"#Simple-FE\" data-toc-modified-id=\"Simple-FE-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Simple FE</a></span></li><li><span><a href=\"#FE\" data-toc-modified-id=\"FE-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>FE</a></span></li></ul></li><li><span><a href=\"#EOF\" data-toc-modified-id=\"EOF-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>EOF</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<br>\n",
    "<span style=\"font-size:30pt; color:darkslateblue;\"><b>\n",
    "Introduction To Named Entity Recognition  \n",
    "</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ner1.png\" alt=\"Drawing\" style=\"width: 700px;\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this analysis,  \n",
    "we use the the following datasets from Kaggle.  \n",
    "  \n",
    "https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:29:55.084166Z",
     "start_time": "2019-03-13T16:29:55.058165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from plotly import tools\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:43:09.489698Z",
     "start_time": "2019-03-13T15:43:09.044673Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./ner_dataset.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:43:09.496699Z",
     "start_time": "2019-03-13T15:43:09.490698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:43:09.526700Z",
     "start_time": "2019-03-13T15:43:09.498699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* POS : Part Of Speech\n",
    "* Tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of tagged entities:\n",
    "\n",
    "'O': 1146068, 'geo-nam': 58388, 'org-nam': 48034, 'per-nam': 23790, 'gpe-nam': 20680, 'tim-dat': 12786, 'tim-dow': 11404, 'per-tit': 9800, 'per-fam': 8152, 'tim-yoc': 5290, 'tim-moy': 4262, 'per-giv': 2413, 'tim-clo': 891, 'art-nam': 866, 'eve-nam': 602, 'nat-nam': 300, 'tim-nam': 146, 'eve-ord': 107, 'per-ini': 60, 'org-leg': 60, 'per-ord': 38, 'tim-dom': 10, 'per-mid': 1, 'art-add': 1\n",
    "\n",
    "Essential info about entities:\n",
    "\n",
    "geo = Geographical Entity  \n",
    "org = Organization  \n",
    "per = Person  \n",
    "gpe = Geopolitical Entity  \n",
    "tim = Time indicator  \n",
    "art = Artifact  \n",
    "eve = Event  \n",
    "nat = Natural Phenomenon  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:59:27.897547Z",
     "start_time": "2019-03-13T16:59:27.846544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.POS.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:59:40.097244Z",
     "start_time": "2019-03-13T16:59:40.046241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Tag.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:43:09.651708Z",
     "start_time": "2019-03-13T15:43:09.528701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35178"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Word.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:43:09.717711Z",
     "start_time": "2019-03-13T15:43:09.685710Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "\n",
    "    def get_next(self):\n",
    "        try:\n",
    "            sent_f = self.data[\"Sentence #\"] == \"Sentence: {}\".format(self.n_sent)\n",
    "            sent_l = self.data[\"Sentence #\"] == \"Sentence: {}\".format(self.n_sent + 1)\n",
    "            s = self.data.iloc[self.data[sent_f].index.item():self.data[sent_l].index.item(), ]\n",
    "            self.n_sent += 1\n",
    "            return s[\"Word\"].values.tolist(), s[\"POS\"].values.tolist(), s[\"Tag\"].values.tolist()\n",
    "        except:\n",
    "            self.empty = True\n",
    "            return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:43:09.753713Z",
     "start_time": "2019-03-13T15:43:09.718711Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sg = SentenceGetter(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:43:09.828718Z",
     "start_time": "2019-03-13T15:43:09.754714Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent, pos, tag = sg.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:43:09.891721Z",
     "start_time": "2019-03-13T15:43:09.830718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.']\n",
      "['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP', 'TO', 'VB', 'DT', 'NN', 'IN', 'NNP', 'CC', 'VB', 'DT', 'NN', 'IN', 'JJ', 'NNS', 'IN', 'DT', 'NN', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sent); print(pos); print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:43:10.173737Z",
     "start_time": "2019-03-13T15:43:09.893721Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MemoryTagger(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Expects a list of words as X and a list of tags as y.\n",
    "        '''\n",
    "        voc = {}\n",
    "        self.tags = []\n",
    "        for x, t in zip(X, y):\n",
    "            if t not in self.tags:\n",
    "                self.tags.append(t)\n",
    "            if x in voc:\n",
    "                if t in voc[x]:\n",
    "                    voc[x][t] += 1\n",
    "                else:\n",
    "                    voc[x][t] = 1\n",
    "            else:\n",
    "                voc[x] = {t: 1}\n",
    "        self.memory = {}\n",
    "        for k, d in voc.items():\n",
    "            self.memory[k] = max(d, key=d.get)\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        '''\n",
    "        Predict the the tag from memory. If word is unknown, predict 'O'.\n",
    "        '''\n",
    "        return [self.memory.get(x, 'O') for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:43:10.203739Z",
     "start_time": "2019-03-13T15:43:10.174738Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger = MemoryTagger()\n",
    "tagger.fit(sent, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:43:10.258742Z",
     "start_time": "2019-03-13T15:43:10.204739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'London': 'B-geo', 'withdrawal': 'O', 'British': 'B-gpe', 'war': 'O', 'that': 'O', 'country': 'O', 'protest': 'O', 'Iraq': 'B-geo', 'from': 'O', 'the': 'O', 'of': 'O', 'through': 'O', 'and': 'O', 'have': 'O', 'marched': 'O', 'in': 'O', '.': 'O', 'demand': 'O', 'demonstrators': 'O', 'troops': 'O', 'Thousands': 'O', 'to': 'O'}\n",
      "['O', 'B-geo', 'B-gpe']\n"
     ]
    }
   ],
   "source": [
    "print(tagger.memory)\n",
    "print(tagger.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:43:10.315746Z",
     "start_time": "2019-03-13T15:43:10.259742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>through</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>London</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>protest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>war</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Iraq</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>demand</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>withdrawal</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>British</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>troops</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>from</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>that</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>country</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sent    tag\n",
       "0       Thousands      O\n",
       "1              of      O\n",
       "2   demonstrators      O\n",
       "3            have      O\n",
       "4         marched      O\n",
       "5         through      O\n",
       "6          London  B-geo\n",
       "7              to      O\n",
       "8         protest      O\n",
       "9             the      O\n",
       "10            war      O\n",
       "11             in      O\n",
       "12           Iraq  B-geo\n",
       "13            and      O\n",
       "14         demand      O\n",
       "15            the      O\n",
       "16     withdrawal      O\n",
       "17             of      O\n",
       "18        British  B-gpe\n",
       "19         troops      O\n",
       "20           from      O\n",
       "21           that      O\n",
       "22        country      O\n",
       "23              .      O"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'sent' : sent, 'tag' : tagger.predict(sent)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:43:10.435752Z",
     "start_time": "2019-03-13T15:43:10.317746Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning:\n",
      "\n",
      "This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:43:10.457754Z",
     "start_time": "2019-03-13T15:43:10.436753Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = data[\"Word\"].values.tolist()\n",
    "tags = data[\"Tag\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:43:14.420980Z",
     "start_time": "2019-03-13T15:43:10.459754Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = cross_val_predict(estimator=MemoryTagger(), X=words, y=tags, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:43:14.426981Z",
     "start_time": "2019-03-13T15:43:14.421980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'O', 'O', ..., 'O', 'O', 'O'], dtype='<U5')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:43:16.391093Z",
     "start_time": "2019-03-13T15:43:14.427981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-art       0.17      0.06      0.09       402\n",
      "      B-eve       0.50      0.25      0.33       308\n",
      "      B-geo       0.78      0.85      0.81     37644\n",
      "      B-gpe       0.94      0.93      0.94     15870\n",
      "      B-nat       0.40      0.30      0.34       201\n",
      "      B-org       0.67      0.48      0.56     20143\n",
      "      B-per       0.76      0.66      0.71     16990\n",
      "      B-tim       0.86      0.77      0.82     20333\n",
      "      I-art       0.04      0.01      0.01       297\n",
      "      I-eve       0.39      0.10      0.16       253\n",
      "      I-geo       0.72      0.58      0.65      7414\n",
      "      I-gpe       0.62      0.45      0.52       198\n",
      "      I-nat       0.00      0.00      0.00        51\n",
      "      I-org       0.68      0.54      0.60     16784\n",
      "      I-per       0.74      0.64      0.69     17251\n",
      "      I-tim       0.58      0.13      0.21      6528\n",
      "          O       0.97      0.99      0.98    887908\n",
      "\n",
      "avg / total       0.94      0.95      0.94   1048575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_pred=pred, y_true=tags)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:46:15.617344Z",
     "start_time": "2019-03-13T15:46:15.112315Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning:\n",
      "\n",
      "numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:45:57.021281Z",
     "start_time": "2019-03-13T15:45:57.017280Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_map(word):\n",
    "    return np.array([word.istitle(), word.islower(), word.isupper(), len(word),\n",
    "                     word.isdigit(),  word.isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:30:02.529592Z",
     "start_time": "2019-03-13T16:30:00.083452Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 1048575/1048575 [00:02<00:00, 457866.80it/s]\n"
     ]
    }
   ],
   "source": [
    "words = [feature_map(w) for w in tqdm(data['Word'].values.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:33:53.619810Z",
     "start_time": "2019-03-13T16:33:00.257758Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = cross_val_predict(\n",
    "    RandomForestClassifier(n_estimators=20), \n",
    "    X=words, \n",
    "    y=tags, \n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:34:17.452173Z",
     "start_time": "2019-03-13T16:34:15.493061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-art       0.00      0.00      0.00       402\n",
      "      B-eve       0.00      0.00      0.00       308\n",
      "      B-geo       0.26      0.79      0.40     37644\n",
      "      B-gpe       0.26      0.06      0.09     15870\n",
      "      B-nat       0.00      0.00      0.00       201\n",
      "      B-org       0.65      0.17      0.27     20143\n",
      "      B-per       0.97      0.20      0.33     16990\n",
      "      B-tim       0.29      0.32      0.30     20333\n",
      "      I-art       0.00      0.00      0.00       297\n",
      "      I-eve       0.00      0.00      0.00       253\n",
      "      I-geo       0.00      0.00      0.00      7414\n",
      "      I-gpe       0.00      0.00      0.00       198\n",
      "      I-nat       0.00      0.00      0.00        51\n",
      "      I-org       0.36      0.03      0.06     16784\n",
      "      I-per       0.47      0.02      0.04     17251\n",
      "      I-tim       0.50      0.06      0.11      6528\n",
      "          O       0.97      0.98      0.97    887908\n",
      "\n",
      "avg / total       0.88      0.87      0.86   1048575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_pred=pred, y_true=tags)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:48:52.515205Z",
     "start_time": "2019-03-13T16:48:52.470202Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class FeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.memory_tagger = MemoryTagger()\n",
    "        self.tag_encoder = LabelEncoder()\n",
    "        self.pos_encoder = LabelEncoder()\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        words = X[\"Word\"].values.tolist()\n",
    "        self.pos = X[\"POS\"].values.tolist()\n",
    "        tags = X[\"Tag\"].values.tolist()\n",
    "        self.memory_tagger.fit(words, tags)\n",
    "        self.tag_encoder.fit(tags)\n",
    "        self.pos_encoder.fit(self.pos)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # helper function to check OOPos or not\n",
    "        def pos_default(p):\n",
    "            if p in self.pos:\n",
    "                return self.pos_encoder.transform([p])[0]\n",
    "            else:\n",
    "                return -1\n",
    "        \n",
    "        pos = X[\"POS\"].values.tolist()\n",
    "        words = X[\"Word\"].values.tolist()\n",
    "        out = []  # output of this function\n",
    "        \n",
    "        for i in tqdm(range(len(words))):\n",
    "            w = words[i]\n",
    "            p = pos[i]\n",
    "            \n",
    "            if i < len(words) - 1:\n",
    "                # wp : previous word, posp : previous pos\n",
    "                wp = self.tag_encoder.transform(self.memory_tagger.predict([words[i+1]]))[0]\n",
    "                posp = pos_default(pos[i+1])\n",
    "            else:\n",
    "                wp = self.tag_encoder.transform(['O'])[0]\n",
    "                posp = pos_default(\".\")\n",
    "            \n",
    "            if i > 0:\n",
    "                if words[i-1] != \".\":\n",
    "                    wm = self.tag_encoder.transform(self.memory_tagger.predict([words[i-1]]))[0]\n",
    "                    posm = pos_default(pos[i-1])\n",
    "                else:\n",
    "                    wm = self.tag_encoder.transform(['O'])[0]\n",
    "                    posm = pos_default(\".\")\n",
    "            else:\n",
    "                posm = pos_default(\".\")\n",
    "                wm = self.tag_encoder.transform(['O'])[0]\n",
    "            \n",
    "            out.append(np.array([\n",
    "                w.istitle(), w.islower(), w.isupper(), len(w), w.isdigit(), w.isalpha(),\n",
    "                self.tag_encoder.transform(self.memory_tagger.predict([w]))[0],  # a little leaky\n",
    "                pos_default(p), \n",
    "                wp, wm, posp, posm]))\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:49:27.502206Z",
     "start_time": "2019-03-13T16:49:27.485205Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T17:27:15.134907Z",
     "start_time": "2019-03-13T17:04:28.910764Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = cross_val_predict(\n",
    "    Pipeline([\n",
    "        (\"feature_map\", FeatureTransformer()),\n",
    "        (\"clf\", RandomForestClassifier(n_estimators=20,\n",
    "                                       n_jobs=3))\n",
    "    ]), X=data, y=tags, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report = classification_report(y_pred=pred, y_true=tags)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EOF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
